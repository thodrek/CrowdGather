\section{Related Work}
\label{sec:related}
The prior work related to the techniques proposed in this paper can be placed in a few categories; we describe each of them in turn:

\vspace{5pt}\noindent\textbf{Crowd Algorithms:} There has been a significant amount of work on designing algorithms where the unit operations are performed by human workers, including the execution of common database query operators such as filter~\cite{crowdscreen}, join~\cite{markus-sorts-joins} and max~\cite{so-who-won},  machine learning~\cite{entity-matching, crowdclustering, crowder} and data mining tasks~\cite{amsterdamer:2013, get-another-label} etc. Previous work on the task of populating a database~\cite{park:2014, trushkowsky:2013} is the most related to ours. However, in both cases authors focus on a single entity extraction query and do consider extracting entities from large and diverse data domains. Moreover, the proposed techniques do not support  dynamic adaptation of the queries issued against the crowd to optimize for a specified monetary budget. 

\vspace{5pt}\noindent\textbf{Knowledge Acquisition Systems:} Recent work has focused on combining crowdsourcing techniques with knowledge acquisition systems~\cite{jiang:13, kondredi:2014, west:2014}. This line of work suggests using the crowd for curating automatically constructed knowledge bases (i.e., assessing the validity of the extracted facts) and for gathering additional knowledge to be added in the knowledge base. Estimating the newly acquired information from a query and then  devising querying strategies that maximize the amount of extracted information will surely be beneficial for knowledge extraction systems.

\vspace{5pt}\noindent\textbf{Deep Web Crawling:} A different line of work has focused on data acquisition from the deep web~\cite{Jin:2011,Sheng:2012}. In such scenarios, data is obtained by querying an interface over a hidden database and extracting results from a dynamically generated answer. Often, such interfaces provide partial answers to issued queries. These answer are usually limited to the top-k tuples based on a database specific ranking function. Sheng et al.~\cite{Sheng:2012} provide near-optimal algorithms that exploit the exposed structure of the underlying domain to extract all the tuples present in the hidden database under consideration. The main difference between this line of work and ours is that answers from a hidden database are deterministic, i.e., a query will always retrieve the same top-k tuples. This assumption does not hold in the crowdsourcing scenario considered in this paper and thus the proposed techniques are not applicable. Since crowdsourced entity extraction queries can be viewed as random samples from an unknown  distribution, one needs to make use of the query result estimation techniques introduced in \Cref{sec:gainestimators}.