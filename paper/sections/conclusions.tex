%!TEX root = ../crowd_hierarchies_v.1.3.tex

\section{Conclusions and Future Work}
\label{sec:conclusions}
In this paper, we studied the problem of crowdsourced entity extraction over large and diverse data domains. We introduced a novel crowdsourced entity extraction framework that combines statistical techniques with an adaptive optimization algorithm to maximize the total number of unique entities extracted. We proposed a new regression-based technique for estimating the gain of further querying when the number of retrieved entities is small with respect to the total size of the underlying population. We also introduced a new algorithm that exploits the often known structure of the underlying data domain to devise adaptive querying strategies. Our experimental results show that our techniques extract up to 4X more entities compared to a collection of baselines, and for large sparse entity domains are at most 25\% away from an omniscient adaptive querying strategy with perfect information.

Some of the future directions for extending this work include reasoning about the quality and correctness of the extracted result as well as extending the proposed techniques to other types of information extraction tasks. As mentioned before, the techniques proposed in this paper do not deal with incomplete and imprecise information. However, there has been an increasing amount of literature on addressing these quality issues in crowdsourcing~\cite{ vox-populii, quality, nushi:14, raykar-whom-to-trust}. Combining these techniques, or entity resolution techniques~\cite{crowder} that reason about similarity of extracted entities, with our proposed framework is a promising future direction. Finally, it is of particular interest to consider how the proposed framework can be applied to other budget sensitive information extraction applications including discovering valuable data sources for integration tasks~\cite{rekatsinas:2015} or curating and completing a knowledge base~\cite{kondredi:2014}.