% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012
% based on ACM SIGPROC-SP.TEX VERSION 2.7
% Modified by  Gerald Weber <gerald@cs.auckland.ac.nz>
% Removed the requirement to include *bbl file in here. (AhmetSacan, Sep2012)
% Fixed the equation on page 3 to prevent line overflow. (AhmetSacan, Sep2012)

\documentclass{sig-alternate}
\usepackage{graphicx}
\usepackage{color}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{times}
\usepackage{url}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage[noend]{algorithmic}
\usepackage{enumerate}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{cleveref}
\newcommand{\squishlist}{
   \begin{list}{$\bullet$}
    {
      \setlength{\itemsep}{0pt}
      \setlength{\parsep}{3pt}
      \setlength{\topsep}{3pt}
      \setlength{\partopsep}{0pt}
      \setlength{\leftmargin}{1.5em}
      \setlength{\labelwidth}{1em}
      \setlength{\labelsep}{0.5em} } }

\newcommand{\squishend}{
    \end{list}  }

\newcommand{\argmax}{\operatornamewithlimits{arg\ max}}

\newcommand{\eat}[1]{}
\newcommand{\todo}[1]{\textcolor{red}{{TODO: #1}}}
\newcommand{\add}[1]{\textcolor{red}{{ADD: #1}}}
\newcommand{\note}[1]{\textcolor{blue}{{#1}}}

\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{problem}{Problem}
\newtheorem{reduction}{Reduction}
\newcommand{\domain}{\mathcal{D}}
\newcommand{\attributes}{\mathcal{A}_D}
\newcommand{\hierarchy}{\mathcal{H}_D}
\newcommand{\attrhierarchy}{\mathcal{H}_A}
\newcommand{\workers}{\mathcal{W}}
\newcommand{\uentities}{\mathcal{E}}
\newcommand{\queryvector}{{\bf Q_S}}



\begin{document}

% ****************** TITLE ****************************************

\title{CrowdGather: Budgeted Entity Extraction over Structured Data Domains}

\numberofauthors{3} 

\author{
}

\maketitle

\begin{abstract}
Crowd entity extraction has become a popular means of acquiring data for many applications, including recommendation systems, listing aggregation and knowledge base compilation.  Most of the current solutions focus on entity extraction for specific queries and do not consider entity extraction over broader entity domains. Due to the time and cost of human labor, considering each query in isolation may incur large costs when applied to broader domains, thus, limiting the applicability of current approaches.
 
In this paper, we explore the problem of {\em budgeted entity extraction} over {\em structured entity domains}. We consider domains that can be fully described by a collection of predicates, each characterized by a hierarchical structure. We develop new statistical tools that enable users to reason about the gain of issuing {\em further queries} in the presence of little information and show how to exploit the dependencies across different points of the data domain to obtain more accurate estimates. We also demonstrate how budgeted entity extraction over large domains can be cast as an adaptive optimization problem that seeks to maximize the number of extracted entities while minimizing the overall extraction cost. We evaluate our techniques with experiments on both synthetic and real-world data. 
\end{abstract}

\section{Introduction}
Combining human computation with traditional computer systems has been recently proven beneficial in extracting knowledge and acquiring data for many application domains, including recommendation systems~\cite{amsterdamer:2014}, knowledge base completion~\cite{kondredi:2014}, entity extraction and structured data collection~\cite{trushkowsky:2013, park:2014}. In fact, extracting information, and entities in particular, from the crowd has been shown to provide access to more fine grained information that may belong to the long tail of the web or even be completely unavailable on the web~\cite{west:2014}.

A fundamental challenge in crowd entity extraction is reasoning about the completeness of the extracted information. More precisely, given a query that seeks to enumerate entities from a specific domain, how can one decide on the completeness of the retrieved entities. Recent work has considered this problem for single queries~\cite{trushkowsky:2013} where the query predicates specify the data domain of interest. Often, however, crowd entity extraction techniques are used to acquire information for large data domains that cannot be described adequately by a single query with fixed predicates. Consider for example a scenario where crowd sourcing techniques are used to collect information about various types of events (e.g., music concerts or political rallies) over different countries. Extracting entities from this domain requires issuing multiple targeted queries requesting the crowd to provide information for specific types of events potentially focusing on a specific location. Crowd entity extraction in such domains entails several challenges. Next, we use a real-world scenario to illustrate these challenges.

\subsection{Challenges and Opportunities}
We consider Eventbrite~\footnote{https://www.eventbrite.com}, an online event aggregator, that relies on crowdsourcing to compile a directory of events with detailed information about the location, type, date and category of each event. Typically, event aggregators are interested in collecting information about diverse events spanning from conferences and music festivals to political rallies for multiple locations across different location, i.e., countries or cities. In particular, Eventbrite collects information about events across different countries in the world. Each country is further split into cities and areas across the country. Moreover, events are organized according to their type and topic. Eventbrite uses 20 different types to characterize events, such as rallies, tournaments, conferences, conventions, etc. and 20 different topics, such as government and politics, health and wellness, music, etc.  to describe each event. Each topic is further split into sub-topics. For example, a  music event can be further described according to its corresponding genre. 

\textcolor{red}{I want to fill this out with plots of eventbrite events}

\ \\First challenge: sparse areas of the data domain. Given a budget might not worth be issuing any queries to extract more events there
\ \\Add a plot showing that for certain location, event type, topic combinations there are no events or a much smaller number of events. 

\ \\Opportunity: Exploit the hierarchical structure of the data domain. Discuss how the structure of Eventbrite's hierarchy can be exploited to discover sparse areas and optimize for the budget.

\ \\Second challenge: Side information. Show example of overlaps. and the fact that when we request events for a location we get many events for a specific topic etc. dependent samples.

\subsection{Contributions}
Motivated by these examples, we study the problem of {\em budgeted crowd entity extraction} over {\em structured domains}. More precisely, we focus on domains described by a collection of predicates, each following a known hierarchical structure. We propose a novel algorithmic framework that exploits the structure of the domain to maximize the number of extracted entities under given budget constraints. In particular, we view the problem of entity extraction as a {\em multi-round adaptive optimization problem}. At  each round we exploit the information on extracted entities obtained by previous queries to adaptively select the crowd query that will maximize the {\em return} and cost trade-off at each round. The return of a query is defined as the number of new unique entities extracted by it. Building upon techniques from the species estimation literature, we introduce a new methodology for estimating the return for generalized queries and show how the hierarchical structure of the domain can be exploited to improve the accuracy of our estimates. Our main contributions are as follows:

\squishlist
\item We study the problem of budgeted entity extraction over structured domains and show how one can exploit the domain structure to maximize the set of extracted entities under budget constraints. 
\item We develop a new technique to estimate the return of generalized entity extraction queries under the presence of dependent samples.
\item We introduce an adaptive optimization algorithm that takes as input the return estimates for different types of queries and identifies querying policies that maximize the total number of retrieved entities under given budget constraints. 
\item Finally, we show that our techniques can effectively solve the problem of budgeted crowd entity extraction for large data domains on both real-world and synthetic data.
\squishend

\section{Preliminaries}
In this section we first review the problem of {\em crowdsourced entity extraction} and different types of crowd entity extraction queries. Then, we formally define the problem of {\em budgeted entity extraction over structured domains}. 

\subsection{Crowd Entity Extraction}
Let $\domain$ be a domain of entities that follows an open-world assumption, that is, incomplete or no information is available about which entities are contained in $\domain$. We assume knowledge of a set of discrete attributes $\attributes = \{A_1, A_2, \dots, A_d\}$ characterizing $\domain$. Let $dom(A_i)$ denote the domain of each attribute $A_i  \in \attributes$. Then, $\domain$ is the Cartesian product of $dom(A_1), \dots, dom(A_d)$. In the reminder of the paper we will refer to each element of the Cartesian product as a {\em point} in $\domain$, i.e., a point is a possible combination of values of all dimensions. We will also refer to a collection of points for which only a subset of attributes shares the same value as a {\em slice} of $\domain$. For example all points for which attribute $A_1 = x$ but all other attributes may take any value constitute a slice. 

The basic version of {\em crowdsourced entity extraction}~\cite{trushkowsky:2013} seeks to enumerate entities that belong in a single slice $\domain_P$ of $\domain$, specified by a set of predicates $P$ over a subset of attributes in $\attributes$. For example, consider the entity domain $\domain$ to be that of all ``Concerts" and the attributes describing the entities in $\domain$ to be $\attributes = \{$``Band Name", ``Location", ``Music Genre"$\}$. An instance of crowdsourced entity extraction corresponds to listing concerts with LOCATION = ``Boston, MA" and GENRE = ``Rock". 

We assume three different types of crowdsourced queries for answering an entity extraction problem as the one described above. The first type corresponds to {\em single entity queries} where workers are required to provide ``one more" entity that satisfies the query predicates. The second type of queries corresponds to {\em queries of  size k} where workers are asked to provide up to $k$ distinct entities. Finally, the last type corresponds to {\em exclude list queries}. Here,  workers are provided with $l$ entities that have already been extracted and are required to provide up to $k$ distinct entities under the constraint that none of them is included in the exclude list. It is easy to see that the last type of queries generalizes the previous two. Therefore, in the remainder of the paper, we will consider that all queries of the third type. To describe a query, we will use the notation $q(k,l)$ denoting a query of size $k$ accompanied with an exclude list of length $l$. 

Assuming an infinite pool of crowd workers,  one can extract entities satisfying a set of desired predicates by repeatedly asking workers queries with different configurations $q(k,l)$ across {\em multiple rounds}. However, in a typical crowdsourcing environment, tasks have different costs depending on their difficulty. Thus, crowdsourced queries of different difficulties should also exhibit different costs. Given a query $q(k,l)$, we assume that its cost is given by a function $c(\dot)$ with the following properties: (a) given an exclude list of fixed length $l$ then $c(q(k^{\prime},l)) \geq c(q(k,l)),  \forall k^{\prime} \geq k$, and (b) given a fixed query size $k$ then $c(q(k,l^{\prime})) \geq c(q(k,l)), \forall l^{\prime} \geq l$. 

The above naturally gives raise to a tradeoff between the total number of extracted entities and the total cost. Let $\pi$ denote a {\em querying policy}, that is, a chain of query configurations defining the crowdsourced queries issued at each round. Moreover, let $\uentities(\pi)$ be the total number of unique entities extracted following policy $\pi$ and $C(\pi)$ be the total cost of following querying policy $\pi$. Finally, we assume a monetary budget $\tau_c$ imposing a constraint on the total cost of a selected querying policy. We define the problem of budgeted crowdsourced entity extraction as follows:

\begin{definition}[Budgeted Entity Extraction]
Let $\domain$ be a given entity domain and $\tau_c$ a monetary budget on the total cost of issued queries. The Budgeted Entity Extraction problem seeks to find 
a querying policy $\pi^*$ that maximizes the number of unique entities extracted $\uentities(\pi^*)$ under the constraint $C(\pi^*) \leq \tau_c$.
\end{definition}

Measuring the effectiveness of different policies on extracting entities requires reasoning about the number of {\em new entities} returned by each query. In the remainder of the paper, we also refer to the number of new entities extracted by a query as the {\em return of the query}. The exact number of new entities returned by each query is unknown before issuing the query and thus one needs to estimated it using the expected number of new entities returned by a query $q(k,l)$. In their recent work, Trushkowsky et al.~\cite{trushkowsky:2013} showed how techniques from the species estimation literature can be used to estimate the new entities returned by queries of the form $q(1,0)$. Furthermore, the authors propose a {\em pay-as-you-go} scheme where one repeatedly issues $q(1,0)$ queries to the crowd until the {\em marginal gain}, i.e., the difference between the new extracted entities and the querying cost, drops below a desired threshold. However, the proposed scheme is agnostic to budget constraints as it does not enforces them explicitly. 

\subsection{Extracting Entities over Hierarchies}

\section{Framework Overview}
\subsection{}
\subsection{}
\subsection{}

\section{The Gain of Further Queries}

\section{Profitable Querying Policies}

\section{Related Work}

\ \\Beth's work
\ \\Tova's work
\ \\CrowdFill work

\section{Conclusions}


\bibliographystyle{abbrv}
\bibliography{crowd_hierarchies}

\end{document}
